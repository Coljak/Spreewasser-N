{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://unidata.github.io/netcdf4-python/\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "from datetime import datetime, timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of dtypes and their netCDF4 equivalents\n",
    "DTYPES = {\n",
    "    'int8': 'i1',\n",
    "    'int16': 'i2',\n",
    "    'int32': 'i4',\n",
    "    'int64': 'i8',\n",
    "    'uint8': 'u1',\n",
    "    'uint16': 'u2',\n",
    "    'uint32': 'u4',\n",
    "    'uint64': 'u8',\n",
    "    'float32': 'f4',\n",
    "    'float64': 'f8',\n",
    "    'str': 'S1'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'zalf_hurs_amber_2007_v1-0.nc'\n",
    "# open netcdf file\n",
    "dwd_path = '../../Geodaten/DWD_SpreeWasser_N/'\n",
    "new_path = '../../Geodaten/DWD_SpreeWasser_N_cf_v6/'\n",
    "if os.path.isfile(os.path.join(dwd_path, file_name)) and file_name.endswith('.nc'):\n",
    "    org = nc.Dataset(os.path.join(dwd_path, file_name))\n",
    "    # extract DWD parameter from all variables in the NetCDF\n",
    "    vars = org.variables.keys()\n",
    "    dwd_param = list(vars)[-1]\n",
    "    \n",
    "    # find the right netCDF4 datatype for creating a netCDF variable\n",
    "    var_dtype = str(org[dwd_param][:].dtype)\n",
    "    nc_type = DTYPES[var_dtype]\n",
    "\n",
    "    # create new dataset with the same dimensions, variable and coordinates as the DWD netcdf files\n",
    "    # cf stands for CF-conform, v4 for version 4\n",
    "    new_file_name = file_name.replace('.nc', '_cf_v6.nc')\n",
    "    fn = os.path.join(new_path, new_file_name)\n",
    "    ds_new = nc.Dataset(fn, 'w', format='NETCDF4', zlib=True, complevel=9)\n",
    "\n",
    "    # create dimensions\n",
    "    time = ds_new.createDimension('time', None) # None is unlimited dimension\n",
    "    lat = ds_new.createDimension('lat', org['lat'].size)\n",
    "    lon = ds_new.createDimension('lon', org['lon'].size)\n",
    "\n",
    "    # create variables for the dimensions\n",
    "    times  = ds_new.createVariable('time', DTYPES[str(org['time'][:].dtype)], ('time',)) # f4 is float32, last argument is dimension tuple\n",
    "    lats  = ds_new.createVariable('lat', DTYPES[str(org['lat'][:].dtype)], ('lat',))\n",
    "    lons  = ds_new.createVariable('lon', DTYPES[str(org['lon'][:].dtype)], ('lon',))\n",
    "    #value = ds_new.createVariable(dwd_param, nc_type, ('time', 'lat', 'lon',))\n",
    "    # Create a variable with compression and chunking options optimized for access of timeseries in one point\n",
    "    time_length = ds_new['time'].shape[0]\n",
    "    value = ds_new.createVariable(dwd_param, nc_type, ('time', 'lat', 'lon'), zlib=True, complevel=9,  chunksizes=(time_length, 1, 1))\n",
    "\n",
    "\n",
    "    # assign the values of the original netcdf file to the new netcdf file\n",
    "    times[:] = org['time'][:]\n",
    "    lats[:] = org['lat'][:]\n",
    "    lons[:] = org['lon'][:]\n",
    "    value[:] = org[dwd_param][:]\n",
    "\n",
    "    # add attributes to dimensions\n",
    "    times.units = org['time'].units\n",
    "    times.calendar = 'gregorian'\n",
    "\n",
    "    lats.units = 'degree_north'\n",
    "    lats.long_name = 'latitude'\n",
    "    lats.standard_name = 'latitude'\n",
    "    lats.axis = 'Y'\n",
    "\n",
    "    lons.units = 'degree_east'\n",
    "    lons.long_name = 'longitude'\n",
    "    lons.standard_name = 'longitude'\n",
    "    lons.axis = 'X'\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # extract global and variable attributes from the original netcdf file (They only attributes are stored with the parameter variable in this case)\n",
    "    value.units = org[dwd_param].units\n",
    "    value.long_name = org[dwd_param].long_name\n",
    "    value.standard_name = org[dwd_param].standard_name\n",
    "    value.institution = org[dwd_param].institution\n",
    "    value.source = org[dwd_param].source\n",
    "    value.contact = org[dwd_param].contact\n",
    "    value.description = org[dwd_param].description\n",
    "    value.data_version = org[dwd_param].data_version   \n",
    "    value.creation_date = org[dwd_param].creation_date\n",
    "    value.history = org[dwd_param].history\n",
    "\n",
    "    value.setncattr('minimum_value', np.nanmin(org[dwd_param][:]))\n",
    "    value.setncattr('maximum_value', np.nanmax(org[dwd_param][:]))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    startdate_str = org['time'].units.split('since')[1].strip()\n",
    "    startdate = datetime.strptime(startdate_str, '%Y-%m-%d %H:%M:%S')\n",
    "    startdate = startdate.strftime('%Y-%m-%d %H:%M:%S') \n",
    "    \n",
    "    min_lon = org['lon'][:].min()\n",
    "    max_lon = org['lon'][:].max()\n",
    "    min_lat = org['lat'][:].min()\n",
    "    max_lat = org['lat'][:].max()\n",
    "\n",
    "\n",
    "    # create all global attributes\n",
    "    global_attrs ={'title': 'DWD ' + org[dwd_param].standard_name.replace('_', ' ') + ' data',\n",
    "                    'Conventions': 'ACDD-1.3, CF-1.11',\n",
    "                    'conventionsURL': 'http://cfconventions.org/Data/cf-conventions/cf-conventions-1.11/cf-conventions.html',\n",
    "                    'keywords': 'DWD, ' + org[dwd_param].standard_name.replace('_', ' '),\n",
    "                    'keywords_vocabulary': 'GCMD Science Keywords',\n",
    "                    'cdm_data_type': 'Grid',\n",
    "                    'creator_name': org[dwd_param].institution,\n",
    "                    'creator_email': org[dwd_param].contact,\n",
    "                    'creator_url': 'www.dwd.de',\n",
    "                    'publisher_name': 'Zentrum f√ºr Agrarlandschaftsforschung (ZALF) e.V.',\n",
    "                    'publisher_email': 'colja.krugmann@zalf.de',\n",
    "                    'publisher_url': 'www.zalf.de',\n",
    "                    'date_metadata_modified': datetime.now().strftime('%Y-%m-%d'),\n",
    "                    'geospatial_bounds': 'POLYGON (({} {}, {} {}, {} {}, {} {}))'.format(\n",
    "                        min_lon, min_lat, max_lon, min_lat, max_lon, max_lat, min_lon, max_lat\n",
    "                    ),\n",
    "                    'geospatial_bounds_crs': 'EPSG:4326',\n",
    "                    'geospatial_lat_min': str(min_lat),\n",
    "                    'geospatial_lat_max': str(max_lat),\n",
    "                    'geospatial_lon_min': str(min_lon),\n",
    "                    'geospatial_lon_max': str(max_lon),\n",
    "                    'time_coverage_start': startdate + 'A', # Timezone UTC+100\n",
    "                    # 'time_coverage_end': str(org['time'][:].max()) + 'A', # Timezone UTC+100, A. \n",
    "                    'time_coverage_resolution': 'P1D',\n",
    "    }\n",
    "\n",
    "    ds_new.setncatts(global_attrs)\n",
    "\n",
    "    # close the new netcdf file\n",
    "    org.close()\n",
    "    ds_new.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_cf_conform_netcdf('zalf_hurs_amber_2007_v1-0.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../Geodaten/DWD_SpreeWasser_N/'\n",
    "file_list = os.listdir(path)\n",
    "for file_name in file_list:\n",
    "    print(file_name)\n",
    "    if file_name.endswith('.nc'):\n",
    "        create_cf_conform_netcdf(file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
