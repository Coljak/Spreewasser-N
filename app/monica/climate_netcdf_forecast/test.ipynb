{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from xml.etree import ElementTree\n",
    "from datetime import datetime, date\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "from django.core.cache import cache\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BASE_CATALOG_URL = \"https://esgf-data.dwd.de/thredds/catalog/esgf3/data/climatepredictionsde/seasonal/output/public/DE-0075x005/DWD/GCFS21/svh2023{month:02}01/sfc{year}{month:02}01/{scenario}/DWD-EPISODES2022/v1-r1/day/{variable}/\"\n",
    "\n",
    "BASE_DOWNLOAD = \"https://esgf-data.dwd.de/thredds/fileServer/esgf3/data/climatepredictionsde/seasonal/output/public/DE-0075x005/DWD/GCFS22/\"\n",
    "BBBBBBBBBBBBB = 'https://esgf-data.dwd.de/thredds/fileServer/esgf3/data/climatepredictionsde/seasonal/output/public/DE-0075x005/DWD/GCFS22/svh20230501/sfc20250501/r1i1p1/DWD-EPISODES2022/v1-r1/day/hurs/v2025506/hurs_day_GCFS22--DWD-EPISODES2022--DE-0075x005_sfc20250501_r1i1p1_20250501-20251130.nc'\n",
    "CCCCCCCCCCCCC = 'https://esgf-data.dwd.de/thredds/fileServer/esgf3/data/climatepredictionsde/seasonal/output/public/DE-0075x005/DWD/GCFS22/svh20230501/sfc20250501/r1i1p1/DWD-EPISODES2022/v1-r1/day/pr/v20250506/pr_day_GCFS22--DWD-EPISODES2022--DE-0075x005_sfc20250501_r12i1p1_20250501-20251130.nc'\n",
    "SCENARIOS = ['r1i1p1', 'r2i1p1', 'r3i1p1']\n",
    "# SCENARIOS = ['r1i1p1']\n",
    "VARIABLES = ['hurs', 'pr', 'psl', 'rsds', 'sfcWind', 'tas', 'tasmax', 'tasmin']\n",
    "THREDDS_NAMESPACE = {\"thredds\": \"http://www.unidata.ucar.edu/namespaces/thredds/InvCatalog/v1.0\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.today()\n",
    "year = today.year\n",
    "month = today.month\n",
    "future_date = today + relativedelta(months=+6)\n",
    "\n",
    "# Move to the first day of the *next* month, then subtract one day\n",
    "last_day_of_month = (future_date.replace(day=1) + relativedelta(months=+1)) - relativedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = 'tas'\n",
    "scenario = 'r1i1p1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_url = f\"{BASE_CATALOG_URL.format(year=year, month=month, scenario=scenario,variable=variable)}catalog.xml\"\n",
    "        \n",
    "catalog = requests.get(catalog_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [404]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_tree = ElementTree.fromstring(catalog.content)\n",
    "\n",
    "catalog = catalog_tree.findall(\".//thredds:catalogRef\", THREDDS_NAMESPACE)\n",
    "latest_versions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_download_url(scenario, variable):\n",
    "    \"\"\"Get the latest catalog URL for the specified year, month, and scenario.\"\"\"\n",
    "\n",
    "    today = datetime.today()\n",
    "    year = today.year\n",
    "    month = today.month\n",
    "    future_date = today + relativedelta(months=+6)\n",
    "\n",
    "    # Move to the first day of the *next* month, then subtract one day\n",
    "    last_day_of_month = (future_date.replace(day=1) + relativedelta(months=+1)) - relativedelta(days=1)\n",
    "\n",
    "    # get the version folder's name\n",
    "    try:\n",
    "        catalog_url = f\"{BASE_CATALOG_URL.format(year=year, month=month, scenario=scenario,variable=variable)}catalog.xml\"\n",
    "        \n",
    "        catalog = requests.get(catalog_url)\n",
    "        catalog_tree = ElementTree.fromstring(catalog.content)\n",
    "        \n",
    "        catalog = catalog_tree.findall(\".//thredds:catalogRef\", THREDDS_NAMESPACE)\n",
    "        latest_versions = []\n",
    "        for catalog_ref in catalog:\n",
    "            latest_versions.append(catalog_ref.attrib['name'])\n",
    "        latest_version = max(latest_versions)\n",
    "\n",
    "        # compose catalog url for the latest version\n",
    "        latest_version_url = f\"{BASE_CATALOG_URL.format(year=year, month=month, scenario=scenario,variable=variable)}{latest_version}/catalog.xml\"\n",
    "        \n",
    "        # Get the dataset name/ urlPath\n",
    "        dataset_name_reponse = requests.get(latest_version_url)\n",
    "        dataset_name_catalog_tree = ElementTree.fromstring(dataset_name_reponse.content)\n",
    "        dataset_name_catalog = dataset_name_catalog_tree.findall(\".//thredds:dataset\", THREDDS_NAMESPACE)\n",
    "        dataset_path = ''\n",
    "        for dataset in dataset_name_catalog:\n",
    "            if dataset.attrib.get('urlPath'):\n",
    "                dataset_path = dataset.attrib['urlPath']\n",
    "\n",
    "        https_download_url = f\"https://esgf-data.dwd.de/thredds/fileServer/{dataset_path}\"\n",
    "        print('https_download_url: ', https_download_url)\n",
    "        return {'success': True, 'url':https_download_url}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching download URL: {e}\")\n",
    "        return {'success': False, 'error': str(e)}\n",
    "    \n",
    "\n",
    "\n",
    "def get_local_path():\n",
    "    \"\"\"Get the base local path for storing NetCDF forecast files.\"\"\"\n",
    "    local = Path(__file__).resolve().parent.parent\n",
    "    return local / 'climate_netcdf_forecast'\n",
    "\n",
    "def fetch_available_variables(catalog_url):\n",
    "    \"\"\"Fetch available variables from the catalog XML, considering namespaces.\"\"\"\n",
    "    response = requests.get(catalog_url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    tree = ElementTree.fromstring(response.content)\n",
    "    # Find all catalogRef elements within the namespace\n",
    "    variables = [\n",
    "        ref.attrib.get(\"name\") for ref in tree.findall(\".//thredds:catalogRef\", THREDDS_NAMESPACE)\n",
    "    ]\n",
    "    \n",
    "    return variables\n",
    "# variables = ['hurs', 'pr', 'psl', 'rsds', 'sfcWind', 'tas', 'tasmax', 'tasmin']\n",
    "\n",
    "def get_last_valid_forecast_date():\n",
    "    nc_folder_path = get_local_path()\n",
    "    nc_folder_path = os.path.join(nc_folder_path, 'r1i1p1/')\n",
    "    netcdf_paths = [f'{nc_folder_path}/{nc}' for nc in os.listdir(nc_folder_path) if nc.endswith('.nc')]\n",
    "    nc_path = netcdf_paths[0]\n",
    "    ds = xr.open_dataset(nc_path)\n",
    "    times = ds.time[:].values\n",
    "    last_valid_date = times[-1]\n",
    "    print('last_valid_date: ', last_valid_date)\n",
    "    return last_valid_date.astype('datetime64[D]').astype(date)\n",
    "\n",
    "def get_last_valid_forecast_date_cached(update=False):\n",
    "    last_valid_forecast_date = cache.get('last_valid_forecast_date')\n",
    "    if last_valid_forecast_date is None or update == True:\n",
    "        last_valid_forecast_date = get_last_valid_forecast_date()\n",
    "        cache.set('last_valid_forecast_date', last_valid_forecast_date, timeout=259200)  # Cache for 72 hours\n",
    "\n",
    "    return last_valid_forecast_date\n",
    "\n",
    "def delete_old_files(folder_path, new_files):\n",
    "    \"\"\"Delete old NetCDF files from the folder that are not in new_files list.\"\"\"\n",
    "    try:\n",
    "        print('delete_old_files: ', folder_path, new_files)\n",
    "        for file in os.listdir(folder_path):\n",
    "            print('delete_old_files: ', file)\n",
    "            if file.endswith('.nc') and file not in new_files:\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                print(f\"Deleting old file: {file_path}\")\n",
    "                os.remove(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting old files: {e}\")\n",
    "\n",
    "\n",
    "def download_and_save_nc_file(nc_url, save_path):\n",
    "    \"\"\"Download and save the NetCDF file to the specified local path.\"\"\"\n",
    "    response = requests.get(nc_url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    filename = nc_url.split(\"/\")[-1]\n",
    "    save_path = Path(save_path)\n",
    "    save_path = save_path / filename\n",
    "    save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(save_path, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "    print(f\"Downloaded: {filename} to {save_path}\")\n",
    "    return filename\n",
    "\n",
    "\n",
    "def automated_thredds_download():\n",
    "    \"\"\"Main function to automate downloads of variables across scenarios.\"\"\"\n",
    "    \n",
    "\n",
    "    local_path = get_local_path()\n",
    "\n",
    "    # Step 1: Iterate through scenarios and variables\n",
    "    \n",
    "    for scenario in SCENARIOS:\n",
    "        new_files = [] \n",
    "        folder_path = f\"{local_path}/{scenario}/\"\n",
    "        for variable in VARIABLES:\n",
    "            print(f\"Processing variable '{variable}' for scenario '{scenario}'...\")\n",
    "\n",
    "            nc_file_url_message = get_download_url(scenario, variable)\n",
    "            if nc_file_url_message['success']:\n",
    "\n",
    "                downloaded_file = download_and_save_nc_file(nc_file_url_message['url'], folder_path)\n",
    "                new_files.append(downloaded_file)\n",
    "                print('new_files: ', new_files)\n",
    "            else:\n",
    "                print(f\"Failed to download {variable} for scenario {scenario}: {nc_file_url_message['error']}\")\n",
    "\n",
    "\n",
    "        if  new_files != []:\n",
    "            print('new_files: ', new_files)\n",
    "            print(f\"Deleting old files for scenario '{scenario}'...\")\n",
    "            delete_old_files(folder_path, new_files)\n",
    "\n",
    "\n",
    "    old_combined_ncs = [f'{local_path}/{nc}' for nc in os.listdir(local_path) if nc.endswith('.nc')]\n",
    "    # print('old_ncs: ', old_ncs)\n",
    "    new_combined_ncs = []\n",
    "\n",
    "    # Combine NetCDF files  into a single file for each scenario\n",
    "    try:\n",
    "        for scenario in SCENARIOS:\n",
    "            folder_path = f\"{local_path}/{scenario}/\"\n",
    "            netcdf_paths = [f'{folder_path}/{nc}' for nc in os.listdir(folder_path) if nc.endswith('.nc')]\n",
    "            \n",
    "            dates = netcdf_paths[0].split('_')[-1].split('.')[0]\n",
    "            filename = f'forecast_{scenario}_{dates}.nc'\n",
    "            file_path = f\"{local_path}/{filename}\"\n",
    "            if file_path not in old_combined_ncs:\n",
    "                ds = xr.open_mfdataset(netcdf_paths, combine='by_coords', compat='override')\n",
    "                ds.to_netcdf(file_path)\n",
    "                ds.close()\n",
    "                new_combined_ncs.append(file_path)\n",
    "                \n",
    "        print('old_ncs: ', old_combined_ncs)\n",
    "        print('new_ncs: ', new_combined_ncs)\n",
    "        if old_combined_ncs != [] and new_combined_ncs != [] and old_combined_ncs.sort() != new_combined_ncs.sort():\n",
    "            for old_nc in old_combined_ncs:\n",
    "                os.remove(old_nc)\n",
    "\n",
    "        get_last_valid_forecast_date_cached(update=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Combining NetCDF files failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = f\"./r1i1p1\"\n",
    "netcdf_paths = [f'{folder_path}/{nc}' for nc in os.listdir(folder_path) if nc.endswith('.nc')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./r1i1p1/psl_day_GCFS22--DWD-EPISODES2022--DE-0075x005_sfc20250501_r1i1p1_20250501-20251130.nc'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netcdf_paths.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_mfdataset(netcdf_paths, combine='by_coords', compat='override')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./r1i1p1/pr_day_GCFS21--DWD-EPISODES2022--DE-0075x005_sfc20250201_r1i1p1_20250201-20250731.nc',\n",
       " './r1i1p1/tasmax_day_GCFS21--DWD-EPISODES2022--DE-0075x005_sfc20250201_r1i1p1_20250201-20250731.nc',\n",
       " './r1i1p1/sfcWind_day_GCFS21--DWD-EPISODES2022--DE-0075x005_sfc20250201_r1i1p1_20250201-20250731.nc',\n",
       " './r1i1p1/tasmin_day_GCFS21--DWD-EPISODES2022--DE-0075x005_sfc20250201_r1i1p1_20250201-20250731.nc',\n",
       " './r1i1p1/rsds_day_GCFS21--DWD-EPISODES2022--DE-0075x005_sfc20250201_r1i1p1_20250201-20250731.nc']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netcdf_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".menv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
